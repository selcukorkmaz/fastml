% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/explain_model.R
\name{explain_model}
\alias{explain_model}
\title{Explain the fastml_model (DALEX + SHAP + Permutation-based VI)}
\usage{
explain_model(
  object,
  method = "dalex",
  features = NULL,
  grid_size = 20,
  shap_sample = 5,
  vi_iterations = 10,
  colormap = "viridis",
  top_features = NULL,
  seed = 123,
  ...
)
}
\arguments{
\item{object}{A \code{fastml_model} object.}

\item{method}{Currently only \code{"dalex"} is supported.}

\item{features}{Character vector of feature names for partial dependence (model profiles). Default NULL.}

\item{grid_size}{Number of grid points for partial dependence. Default 20.}

\item{shap_sample}{Integer number of observations from processed training data to compute SHAP values for. Default 5.}

\item{vi_iterations}{Integer. Number of permutations for variable importance. Default 10.}

\item{colormap}{Character. Name of a color palette to use (e.g., "viridis"). Default "viridis".}

\item{top_features}{Integer. Limit the SHAP summary plot to top N features by mean abs SHAP. Default NULL (no limit).}

\item{seed}{Integer. A value specifying the random seed.}

\item{...}{Additional arguments (not currently used).}
}
\value{
Prints DALEX explanations: variable importance table & plot, model profiles (if any), SHAP table & summary plot, and optionally a calibration plot.
}
\description{
Provides model explainability using DALEX. This function:
\itemize{
  \item Creates a DALEX explainer.
  \item Computes permutation-based variable importance with boxplots showing variability, displays the table and plot.
  \item Computes partial dependency-like model profiles if `features` are provided.
  \item Computes Shapley values (SHAP) for a sample of the training observations, displays the SHAP table,
  and plots a summary bar chart of \eqn{\text{mean}(\vert \text{SHAP value} \vert)} per feature. For classification, it shows separate bars for each class.
}
}
\details{
\enumerate{
   \item \bold{Custom number of permutations for VI (vi_iterations):}

   You can now specify how many permutations (B) to use for permutation-based variable importance.
   More permutations yield more stable estimates but take longer.

   \item \bold{Custom color palette (colormap):}

   A `colormap` parameter allows you to select a color palette (e.g., "viridis") for SHAP summary plots and variable importance plots.
   This improves aesthetics over default palettes.

   \item \bold{Top Features in SHAP Summary (top_features):}

   You can limit the SHAP summary plot to the top N features by mean absolute SHAP value. This helps focus on the most influential features.

   \item \bold{Support for calibration plot if probably is available (calibration):}

   If `calibration = TRUE` and `probably` is installed, it attempts to produce a model-based calibration plot (e.g., `cal_plot_logistic`).
   This provides a smoothed, nonparametric view of model calibration.

   \item \bold{Better error messages and checks:}

   Improved checks and messages if certain packages or conditions are not met.
 }
}
